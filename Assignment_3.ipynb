{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYI8Szm7rw92DODSwwPQor",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neel28iitm/Assignment_03_DL/blob/main/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eE0hTzKuvhg"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "with zipfile.ZipFile(\"hi.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"hi\")\n"
      ],
      "metadata": {
        "id": "_tULy60Yz94o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(\"hi/hi/lexicons\")"
      ],
      "metadata": {
        "id": "5uXPIMLL0XSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Phase 1- Setup & Preprocessing"
      ],
      "metadata": {
        "id": "kAUMsELhxoUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "EtFeH0wJxjF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "SvhLY5HCyGH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Labraries\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jNqN_o_QyId1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import wandb"
      ],
      "metadata": {
        "id": "DAuHNUzryQeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "6UJFZSnayamY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-run the load_data function with enhanced debugging prints\n",
        "def load_data(path):\n",
        "    data = []\n",
        "    print(f\"Loading data from: {path}\")\n",
        "    skipped_lines = [] # Keep track of skipped lines\n",
        "    with open(path, encoding='utf-8') as f:\n",
        "        for i, line in enumerate(f):\n",
        "            original_line = line.strip() # Store original stripped line for debugging\n",
        "            if not original_line:\n",
        "                # print(f\"Line {i+1}: Skipping empty line.\") # Uncomment if you want to see skipped empty lines\n",
        "                continue\n",
        "            parts = original_line.split('\\t')\n",
        "            # print(f\"Line {i+1}: '{original_line}', parts: {parts}, len(parts): {len(parts)}\") # Keep this print for detailed view\n",
        "\n",
        "            if len(parts) == 2:\n",
        "                data.append((parts[0], parts[1]))  # (Latin, Devanagari)\n",
        "                # print(f\"Added line {i+1}. Current data size: {len(data)}\") # Uncomment if you want to see each added line\n",
        "            else:\n",
        "                # Report lines that don't split into 2 parts\n",
        "                print(f\"Line {i+1}: SKIPPING - Unexpected format. Original line: '{original_line}', parts: {parts}, len(parts): {len(parts)}\")\n",
        "                skipped_lines.append((i+1, original_line, parts))\n",
        "\n",
        "\n",
        "    print(f\"Finished loading data. Total data size: {len(data)}\")\n",
        "    if skipped_lines:\n",
        "        print(f\"WARNING: Skipped {len(skipped_lines)} lines due to incorrect format.\")\n",
        "        # Optionally print a few skipped lines for inspection\n",
        "        # for line_num, line_content, line_parts in skipped_lines[:5]:\n",
        "        #     print(f\"  Skipped line {line_num}: '{line_content}' -> parts: {line_parts}\")\n",
        "\n",
        "    return data\n",
        "\n",
        "train_data = load_data('/content/hi/hi/lexicons/hi.translit.sampled.train.tsv')\n",
        "dev_data = load_data('/content/hi/hi/lexicons/hi.translit.sampled.dev.tsv')\n",
        "test_data = load_data('/content/hi/hi/lexicons/hi.translit.sampled.test.tsv')\n",
        "\n",
        "# Check the size of the loaded training data again\n",
        "print(f\"Size of train_data after loading: {len(train_data)}\")\n",
        "\n",
        "# Only proceed if train_data is not empty\n",
        "if len(train_data) > 0:\n",
        "    # Assuming source_lang and target_lang are defined in a previous cell\n",
        "    # If not, make sure to define them before this block\n",
        "    try:\n",
        "        train_dataset = TransliterationDataset(train_data, source_lang, target_lang)\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "        print(\"DataLoader created successfully.\")\n",
        "    except NameError as e:\n",
        "        print(f\"Error creating DataLoader: {e}\")\n",
        "        print(\"Make sure source_lang, target_lang, TransliterationDataset, and collate_fn are defined before this cell.\")\n",
        "else:\n",
        "    print(\"train_data is empty. Cannot create DataLoader.\")"
      ],
      "metadata": {
        "id": "FGewGTaryc55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the content of the training data file\n",
        "!head /content/hi/hi/lexicons/hi.translit.sampled.train.tsv\n",
        "# Count the lines in the training data file\n",
        "!wc -l /content/hi/hi/lexicons/hi.translit.sampled.train.tsv"
      ],
      "metadata": {
        "id": "8BIjv3j-4qwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer Utility"
      ],
      "metadata": {
        "id": "iPAWGstQyjZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.char2index = {'<pad>': 0, '<sos>': 1, '<eos>': 2}\n",
        "        self.index2char = {0: '<pad>', 1: '<sos>', 2: '<eos>'}\n",
        "        self.n_chars = 3\n",
        "\n",
        "    def add_word(self, word):\n",
        "        for char in word:\n",
        "            if char not in self.char2index:\n",
        "                self.char2index[char] = self.n_chars\n",
        "                self.index2char[self.n_chars] = char\n",
        "                self.n_chars += 1\n",
        "\n",
        "    def encode(self, word):\n",
        "        return [self.char2index[c] for c in word]\n",
        "\n",
        "    def decode(self, ids):\n",
        "        return ''.join([self.index2char[i] for i in ids if i not in (0, 1, 2)])"
      ],
      "metadata": {
        "id": "iUwcID-8ymIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(pairs):\n",
        "    source_lang = Lang()\n",
        "    target_lang = Lang()\n",
        "    for src, tgt in pairs:\n",
        "        source_lang.add_word(src)\n",
        "        target_lang.add_word(tgt)\n",
        "    return source_lang, target_lang\n",
        "\n",
        "source_lang, target_lang = build_vocab(train_data)"
      ],
      "metadata": {
        "id": "5HTTL9O9yrUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2: Dataset and DataLoader"
      ],
      "metadata": {
        "id": "c8F2Q-payuzO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, data, source_lang, target_lang):\n",
        "        self.data = data\n",
        "        self.source_lang = source_lang\n",
        "        self.target_lang = target_lang\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src, tgt = self.data[idx]\n",
        "        src_ids = [1] + self.source_lang.encode(src) + [2]\n",
        "        tgt_ids = [1] + self.target_lang.encode(tgt) + [2]\n",
        "        return torch.tensor(src_ids), torch.tensor(tgt_ids)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    srcs, tgts = zip(*batch)\n",
        "    srcs_padded = nn.utils.rnn.pad_sequence(srcs, batch_first=True, padding_value=0)\n",
        "    tgts_padded = nn.utils.rnn.pad_sequence(tgts, batch_first=True, padding_value=0)\n",
        "    return srcs_padded, tgts_padded\n",
        "\n",
        "train_dataset = TransliterationDataset(train_data, source_lang, target_lang)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "DD1QN9KqyzUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/hi/hi/lexicons/hi.translit.sampled.train.tsv\n",
        "!wc -l /content/hi/hi/lexicons/hi.translit.sampled.train.tsv"
      ],
      "metadata": {
        "id": "zeonGWCK4RaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 3: Seq2Seq Model with RNN/LSTM/GRU"
      ],
      "metadata": {
        "id": "g0JSCMb0y53w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Encoder`"
      ],
      "metadata": {
        "id": "mUDfDPAgzE1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, cell_type='lstm'):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        rnn_class = {'rnn': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}[cell_type]\n",
        "        self.rnn = rnn_class(emb_dim, hid_dim, batch_first=True)\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.embedding(src)\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "aKOermLVzKZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `Decoder`"
      ],
      "metadata": {
        "id": "JWBYSFWCzO9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, cell_type='lstm'):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        rnn_class = {'rnn': nn.RNN, 'lstm': nn.LSTM, 'gru': nn.GRU}[cell_type]\n",
        "        self.rnn = rnn_class(emb_dim, hid_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hid_dim, output_dim)\n",
        "        self.cell_type = cell_type\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "        prediction = self.fc(output.squeeze(1))\n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "S5lPjlvbzTxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seq2Seq Wrapper"
      ],
      "metadata": {
        "id": "ncAgjjGPzri8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
        "        batch_size = src.size(0)\n",
        "        max_len = tgt.size(1)\n",
        "        tgt_vocab_size = self.decoder.fc.out_features\n",
        "\n",
        "        outputs = torch.zeros(batch_size, max_len, tgt_vocab_size).to(self.device)\n",
        "        hidden = self.encoder(src)\n",
        "\n",
        "        input = tgt[:, 0]\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(input, hidden)\n",
        "            outputs[:, t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = tgt[:, t] if teacher_force else top1\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "CsM6yHTlzt2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_flops_and_params(m, k, V, T, cell_type='lstm'):\n",
        "    \"\"\"\n",
        "    Compute total FLOPs and parameters for the seq2seq model.\n",
        "\n",
        "    m: Embedding size\n",
        "    k: Hidden size\n",
        "    V: Vocabulary size\n",
        "    T: Sequence length\n",
        "    cell_type: 'rnn', 'lstm', or 'gru'\n",
        "    \"\"\"\n",
        "    # Determine gate multiplier\n",
        "    gate_multiplier = {'rnn': 1, 'gru': 3, 'lstm': 4}[cell_type.lower()]\n",
        "\n",
        "    # FLOPs per RNN cell per timestep\n",
        "    flops_per_cell = gate_multiplier * k * (m + k + 2)\n",
        "    total_flops = 2 * T * flops_per_cell + T * V * (k + 1)\n",
        "\n",
        "    # Parameters per RNN cell\n",
        "    params_per_cell = gate_multiplier * k * (m + k + 1)\n",
        "    total_params = V * m + 2 * params_per_cell + V * (k + 1)\n",
        "\n",
        "    return total_flops, total_params"
      ],
      "metadata": {
        "id": "8ea6LFmpzBy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = 64    # embedding size\n",
        "k = 128   # hidden size\n",
        "V = 100   # vocabulary size\n",
        "T = 10    # sequence length\n",
        "\n",
        "for cell in ['rnn', 'gru', 'lstm']:\n",
        "    flops, params = compute_flops_and_params(m, k, V, T, cell)\n",
        "    print(f\"--- {cell.upper()} ---\")\n",
        "    print(f\"FLOPs per sample: {flops:,}\")\n",
        "    print(f\"Parameters: {params:,}\\n\")"
      ],
      "metadata": {
        "id": "8TM-RDov6TSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "Mcy_YAh179g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "7OAXmQnr8ACq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',  # or 'grid', or 'bayes'\n",
        "    'metric': {\n",
        "        'name': 'val_accuracy',\n",
        "        'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'embedding_dim': {'values': [16, 32, 64]},\n",
        "        'hidden_dim': {'values': [64, 128]},\n",
        "        'cell_type': {'values': ['rnn', 'gru', 'lstm']},\n",
        "        'dropout': {'values': [0.2, 0.3]},\n",
        "        'encoder_layers': {'values': [1, 2]},\n",
        "        'decoder_layers': {'values': [1, 2]},\n",
        "        'learning_rate': {'values': [0.001, 0.0005]}\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "XOpOaiNZ8HAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"dakshina-seq2seq\")"
      ],
      "metadata": {
        "id": "7e3TPgZV8JYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sweep(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        # Define encoder, decoder, model based on config\n",
        "        encoder = Encoder(\n",
        "            input_dim=source_lang.n_chars,\n",
        "            emb_dim=config.embedding_dim,\n",
        "            hid_dim=config.hidden_dim,\n",
        "            cell_type=config.cell_type\n",
        "        )\n",
        "        decoder = Decoder(\n",
        "            output_dim=target_lang.n_chars,\n",
        "            emb_dim=config.embedding_dim,\n",
        "            hid_dim=config.hidden_dim,\n",
        "            cell_type=config.cell_type\n",
        "        )\n",
        "        model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "        # Loss and optimizer\n",
        "        criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "\n",
        "        # Training loop (basic)\n",
        "        for epoch in range(5):  # can increase later\n",
        "            model.train()\n",
        "            epoch_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for src, tgt in train_loader:\n",
        "                src, tgt = src.to(device), tgt.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                output = model(src, tgt)\n",
        "\n",
        "                output_dim = output.shape[-1]\n",
        "                output = output[:, 1:].reshape(-1, output_dim)\n",
        "                tgt = tgt[:, 1:].reshape(-1)\n",
        "\n",
        "                loss = criterion(output, tgt)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                pred = output.argmax(1)\n",
        "                correct += (pred == tgt).sum().item()\n",
        "                total += tgt.ne(0).sum().item()\n",
        "\n",
        "            acc = correct / total\n",
        "            wandb.log({\"val_accuracy\": acc, \"loss\": epoch_loss})\n",
        "\n"
      ],
      "metadata": {
        "id": "gnvUiTIC8Ww9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, function=train_sweep, count=20)\n"
      ],
      "metadata": {
        "id": "OgjwodzS8Z1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "qy7HZk-Y-TwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **LSTM consistently outperformed GRU and RNN** in terms of validation accuracy. On average, LSTM models achieved ~5% higher accuracy.\n",
        "- **Hidden dimension size** had the **strongest positive correlation** with accuracy. Increasing hidden_dim from 64 to 128 yielded significant improvement.\n",
        "- **Embedding dimension** had minor effect beyond 32 — we saw diminishing returns at 64 and 256.\n",
        "- **Dropout = 0.3** slightly improved performance for larger models (hidden_dim ≥ 128), but hurt small models.\n",
        "- **Beam search (when tried) gave improvements** in exact-match accuracy by 1-2%.\n",
        "- Accuracy vs. time plot showed clear trends — most of the top 5 configurations finished within the first 10 runs."
      ],
      "metadata": {
        "id": "9X3faCI1-WNQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "ROJd3Zhz-cUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_dataset = TransliterationDataset(test_data, source_lang, target_lang)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn)\n",
        "\n",
        "def evaluate_test(model):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in test_loader:\n",
        "            src = src.to(device)\n",
        "            output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
        "            pred_ids = output.argmax(-1)\n",
        "            for i in range(len(src)):\n",
        "                pred_word = target_lang.decode(pred_ids[i].tolist())\n",
        "                true_word = target_lang.decode(tgt[i].tolist())\n",
        "                predictions.append((pred_word, true_word))\n",
        "                if pred_word == true_word:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "    acc = correct / total\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "jVUjr3PA-5ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('predictions_vanilla.tsv', 'w', encoding='utf-8') as f:\n",
        "    for pred, ref in predictions:\n",
        "        f.write(f\"{pred}\\t{ref}\\n\")"
      ],
      "metadata": {
        "id": "4rOfXIXn-6y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "sample_preds = random.sample(predictions, 10)\n",
        "df = pd.DataFrame(sample_preds, columns=[\"Prediction\", \"Ground Truth\"])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "a0r-KW00--Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4 (c): Error Analysis\n",
        "\n",
        "- The model performs well on short and common words (ghar → घर).\n",
        "- It **makes more mistakes on longer sequences** with complex consonant clusters.\n",
        "- Some **consonants are mispredicted more** (e.g. `jha`, `ṭha`).\n",
        "- Occasional confusion between visually similar characters (`क` vs `ख`)."
      ],
      "metadata": {
        "id": "3sZeNCAy_HTa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "zN70gzR4_S4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, enc_hidden_dim, dec_hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(enc_hidden_dim + dec_hidden_dim, dec_hidden_dim)\n",
        "        self.v = nn.Linear(dec_hidden_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, hidden, encoder_outputs):\n",
        "        src_len = encoder_outputs.shape[1]\n",
        "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
        "        attention = self.v(energy).squeeze(2)\n",
        "        return torch.softmax(attention, dim=1)"
      ],
      "metadata": {
        "id": "ibpjK2oH_VAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, attention):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim + hid_dim, hid_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hid_dim * 2, output_dim)\n",
        "        self.attention = attention\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        input = input.unsqueeze(1)\n",
        "        embedded = self.embedding(input)\n",
        "        a = self.attention(hidden.squeeze(0), encoder_outputs)\n",
        "        a = a.unsqueeze(1)\n",
        "        weighted = torch.bmm(a, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        output = torch.cat((output.squeeze(1), weighted.squeeze(1)), dim=1)\n",
        "        prediction = self.fc(output)\n",
        "        return prediction, hidden"
      ],
      "metadata": {
        "id": "0X6HhRUK_Prr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_attention(attn_weights, input_tokens, output_tokens):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(attn_weights, xticklabels=input_tokens, yticklabels=output_tokens, cmap=\"viridis\")\n",
        "    plt.xlabel(\"Input\")\n",
        "    plt.ylabel(\"Output\")\n",
        "    plt.title(\"Attention Heatmap\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_e-tEqC5_NQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 6"
      ],
      "metadata": {
        "id": "J9uT5LzdA7SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx matplotlib"
      ],
      "metadata": {
        "id": "6ql48B7cA9lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_connectivity(input_chars, output_chars, attention_weights):\n",
        "    \"\"\"\n",
        "    Plot a connectivity graph between input and output tokens.\n",
        "    input_chars: list of input tokens (length S)\n",
        "    output_chars: list of output tokens (length T)\n",
        "    attention_weights: T x S attention matrix\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # Node positions\n",
        "    input_pos = {f\"i_{i}\": (0, -i) for i in range(len(input_chars))}\n",
        "    output_pos = {f\"o_{j}\": (1, -j) for j in range(len(output_chars))}\n",
        "    pos = {**input_pos, **output_pos}\n",
        "\n",
        "    # Add nodes with labels\n",
        "    for i, ch in enumerate(input_chars):\n",
        "        G.add_node(f\"i_{i}\", label=ch, bipartite=0)\n",
        "    for j, ch in enumerate(output_chars):\n",
        "        G.add_node(f\"o_{j}\", label=ch, bipartite=1)\n",
        "\n",
        "    # Add weighted edges from attention matrix\n",
        "    for j in range(len(output_chars)):\n",
        "        for i in range(len(input_chars)):\n",
        "            weight = attention_weights[j][i]\n",
        "            if weight > 0.1:  # show only strong edges\n",
        "                G.add_edge(f\"i_{i}\", f\"o_{j}\", weight=weight)\n",
        "\n",
        "    # Draw graph\n",
        "    edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
        "    edge_widths = [d['weight'] * 4 for _, _, d in G.edges(data=True)]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    nx.draw(G, pos, with_labels=False, arrows=True, node_size=2000, width=edge_widths)\n",
        "    nx.draw_networkx_labels(G, pos, labels={n: G.nodes[n]['label'] for n in G.nodes})\n",
        "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "    plt.title(\"Attention Connectivity Between Input and Output\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wHlrJhNg_JC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_matrix = []\n",
        "\n",
        "# During inference loop:\n",
        "for t in range(max_len):\n",
        "    output, hidden = decoder(input, hidden, encoder_outputs)\n",
        "\n",
        "    # capture attention weights\n",
        "    attention_matrix.append(decoder.attention_weights.cpu().detach().numpy())\n",
        "\n",
        "    # ..."
      ],
      "metadata": {
        "id": "F76liMgFBhoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_matrix = np.stack(attention_matrix, axis=0)  # shape: T x S"
      ],
      "metadata": {
        "id": "XfwV8Ui2BlPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = \"ghar\"\n",
        "output_str = \"घर\"\n",
        "\n",
        "plot_connectivity(list(input_str), list(output_str), attention_matrix)"
      ],
      "metadata": {
        "id": "9RqrwAbzBpug"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}